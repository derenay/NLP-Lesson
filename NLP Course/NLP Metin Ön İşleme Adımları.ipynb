{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Metin Ã–n Ä°ÅŸleme AdÄ±mlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords Ã‡Ä±karma\n",
    "Stopwords, baÄŸlaÃ§lar, zamirler gibi anlam aÃ§Ä±sÄ±ndan Ã§ok fazla bilgi taÅŸÄ±mayan kelimelerdir. Ã–rneÄŸin, \"ve\", \"ile\", \"bir\", \"ama\" gibi kelimeler genellikle Ã§Ä±karÄ±lÄ±r.\n",
    "\n",
    "ğŸ“Œ Ã–rnek: Girdi metin: \"Bu bir test cÃ¼mlesidir ve gereksiz kelimeleri Ã§Ä±karmalÄ±yÄ±z.\"\n",
    "\n",
    "Stopwords Ã‡Ä±karÄ±ldÄ±ktan Sonra: [\"Bu\", \"test\", \"cÃ¼mlesidir\", \"gereksiz\", \"kelimeleri\", \"Ã§Ä±karmalÄ±yÄ±z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erenay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('turkish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bir', 'test', 'cÃ¼mlesidir', 'gereksiz', 'kelimeleri', 'Ã§Ä±karmalÄ±yÄ±z', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Bu bir test cÃ¼mlesidir ve gereksiz kelimeleri Ã§Ä±karmalÄ±yÄ±z.\"\n",
    "tokens = word_tokenize(text)\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization ve Stemming\n",
    "\n",
    "Bu adÄ±mlar, kelimeleri kÃ¶klerine indirgeme iÅŸlemleridir.\n",
    "\n",
    "Stemmer (KÃ¶k Bulma)\n",
    "Stemming, kelimenin son eklerini keserek kÃ¶kÃ¼nÃ¼ bulmaya Ã§alÄ±ÅŸÄ±r. Ancak bu yÃ¶ntem dilbilgisel olarak hatalÄ± sonuÃ§lar verebilir.\n",
    "\n",
    "ğŸ“Œ Ã–rnek:\n",
    "\n",
    "\"KoÅŸuyorum\" â†’ \"KoÅŸ\"\n",
    "\"KitaplarÄ±\" â†’ \"Kitap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "book\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"running\"))\n",
    "print(stemmer.stem(\"books\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization (KÃ¶kleÅŸtirme)\n",
    "Lemmatization, kelimenin anlamÄ±nÄ± koruyarak kÃ¶kÃ¼ne indirir. Stemmingâ€™e gÃ¶re daha doÄŸru sonuÃ§lar verir.\n",
    "\n",
    "ğŸ“Œ Ã–rnek:\n",
    "\n",
    "\"KoÅŸuyorum\" â†’ \"KoÅŸmak\"\n",
    "\"KitaplarÄ±\" â†’ \"Kitap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "book\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize('running', pos='v'))\n",
    "print(lemmatizer.lemmatize('books'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging (Kelime TÃ¼rÃ¼ Etiketleme)\n",
    "POS Tagging, kelimelerin cÃ¼mledeki tÃ¼rlerini belirlemektir. Ã–rneÄŸin, isim (noun), fiil (verb), sÄ±fat (adjective) gibi tÃ¼rlere ayrÄ±lÄ±r.\n",
    "\n",
    "ğŸ“Œ Ã–rnek:\n",
    "\n",
    "\"KoÅŸuyorum\" â†’ Fiil (Verb)\n",
    "\"GÃ¼zel\" â†’ SÄ±fat (Adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "tokens = word_tokenize(\"GÃ¼zel bir gÃ¼n baÅŸladÄ±.\")\n",
    "print(pos_tag(tokens))  # [('GÃ¼zel', 'JJ'), ('bir', 'DT'), ('gÃ¼n', 'NN'), ('baÅŸladÄ±', 'VBD')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "Named Entity Recognition (NER), metindeki Ã¶zel isimleri (ÅŸahÄ±s, mekan, organizasyon vb.) belirlemek iÃ§in kullanÄ±lÄ±r.\n",
    "\n",
    "ğŸ“Œ Ã–rnek:\n",
    "Metin: \"Elon Musk, SpaceX ÅŸirketini kurdu ve Mars'a insan gÃ¶ndermeyi planlÄ±yor.\"\n",
    "\n",
    "Elon Musk â†’ KiÅŸi (Person)\n",
    "SpaceX â†’ Organizasyon (Organization)\n",
    "Mars â†’ Yer (Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Elon Musk founded SpaceX and plans to send humans to Mars.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)  # \"Elon Musk PERSON\", \"SpaceX ORG\", \"Mars LOC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metin Normalizasyonu\n",
    "BazÄ± metinlerde farklÄ± yazÄ±m tÃ¼rleri olabilir. NLP iÃ§in metni tutarlÄ± hale getirmek gerekir.\n",
    "\n",
    "ğŸ“Œ Ã–rnek:\n",
    "\n",
    "BÃ¼yÃ¼k-kÃ¼Ã§Ã¼k harf dÃ¶nÃ¼ÅŸÃ¼mÃ¼: \"MERHABA\" â†’ \"merhaba\"\n",
    "Noktalama iÅŸaretlerinin kaldÄ±rÄ±lmasÄ±: \"Merhaba! NasÄ±lsÄ±n?\" â†’ \"Merhaba NasÄ±lsÄ±n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merhaba nasÄ±lsÄ±n\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Merhaba! NasÄ±lsÄ±n?\"\n",
    "clean_text = re.sub(r'[^\\w\\s]', '', text.lower())  # Noktalama kaldÄ±rma ve kÃ¼Ã§Ã¼ltme\n",
    "print(clean_text)  # \"merhaba nasÄ±lsÄ±n\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
